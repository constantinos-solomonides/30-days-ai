# AI Day 07 - First weeks retrospective

## TL;DR

- Writing speed increased during the experiment
- Coding with AI starts fast, converges really slow
- Bootstrapping a sandbox environment way more challenging than expected
- AI introduces a lot of needless complexity
- 20/80 is too optimistic, had to downgrade expectations to 40/60

Results from first week remain a mixed back. I remain cautiously optimistic, and feel justified in my "eager junior Software Engineer" approach for AI.

---

## Introduction

For thirty days I will be running an experiment where using AI as much as possible, documenting the outcomes of each day. To avoid drops in model quality mid-interaction skewing results, I'm using the "Plus" tier of ChatGPT. I plan on using it in a bootstrapping way to build a sandbox via interactive prompt, in which I'll run a local agent, to re-develop an tool I created as part of a previous employment. This will allow me to compare effort and outcomes, which is not possible with something that is entirely new. Building the sandbox myself rather than finding one that's ready has the same motive. I can ballpark the effort to do it manually, I will know what it really too if I do it on my own. Using a ready-made one will mask the human / AI work.

To decide success or failure, the Pareto principle, or 20/80 rule, is used. This means that if by 20% of the manual effort to write prompts gets me to 80% of the finished product, I consider the outcome success. This applies to both doing the coding, as well as writing the articles after.

Overall, although I am a professed skeptic about AI, it's mostly about the hype rather than the tool. As per Amara's law:

> We tend to overestimate the effect of a technology in the short run and underestimate the effect in the long run

For this reason, I distrust not only those who over-hype it as snake-oil salespeople, but also those who downplay it too much. I fully expect a transformation. I do not believe it will be an apocalypse.

------------------------------------------------------------------------

## Writing Experience

Writing output increased quickly. Drafts assemble faster. Structure
appears earlier in the process. It is easier to expand notes into full
sections. Still, the articles take too many iteration. The language is pompous-like and it has a "LinkedIn lying influencer" smell. Too much fluff, too many big words. Giving specs with documents only does so much.

For example, this word-salad comes from an iteration of this article:

> Iterations increases API usage. Costs accumulate mainly during debugging loops. Output gains in drafting do not remove engineering convergence overhead.

On top of it, when writing with AI, language becomes smoother but less distinct. Sentence rhythm standardizes, to the point it's identifiable when you know what to look for. The articles are coming out faster, but they're not "mine" in most meaningful ways and they're often rephrased in ways that are biased in ways I explicitly say "no" to. AI advertises AI.


LinkedIn posts do better because of how LinkedIn posts look already. It helps that the task is usually "shorten this final article", instead of "write the article based on this prompt"


## Coding Experience

Coding with AI is a difficult experience. Generated code often appears correct
but contains small logical gaps. Fixing one issue will reveal another.
Debugging becomes iterative and arduous when playing the Chinese room between two machines

The model performs well with tightly defined tasks. The reliability for wider solutions is low. Context handling weakens across correction cycles. Convergence can require multiple prompt rounds, if it happens at all. There's also the natural skewing that happens because the person writing the prompts is a Software Engineer. I've been telling machines to do things for a long while. Doing it now in a more free-form way doesn't mean I don't start with an advantage.

Despite all the effort, sandbox remains unrealized.
Without it, I do not dare give access to my machine to an agent. I try to learn my lessons from others' cautionary tales. Not become one.

In the end, I had to both do manual work for a day and downgrade my expectations for success to 40/60. That's not a failure of the experiment, but an outcome


## Pay-to-win

AI is a product, and as such, money is a big differentiator. It costs to use the better models online, it costs to buy equipment to run the agents locally, and the way it converges over multiple iterations means that the bigger the project, the bigger the cost.

------------------------------------------------------------------------

## Broader Concerns

### Environmental Impact

Large-scale systems require substantial energy and resources.

### Knowledge Work Displacement

Pattern-based cognitive tasks appear more exposed than high-context
engineering work.

### Concentration of Power

Infrastructure and model ownership remain centralized. Dependency risk
is structural.

### Acceleration vs Exploitation

Acceleration increases output for structured professionals. It may also
increase pressure on adjacent roles.

------------------------------------------------------------------------

## Conclusion

After one week, AI tools assist structured drafting but struggle with
stable engineering convergence. Replacement narratives are not supported
by current results. I will continue testing before forming stronger
conclusions.
